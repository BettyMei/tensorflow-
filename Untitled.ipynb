{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(x):  \n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "  \n",
    "def logistic_derivative(x):  \n",
    "    return logistic(x) * (1 - logistic(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#神经元类\n",
    "class Neuron:  \n",
    "    def __init__(self, len_input):  \n",
    "        self.weights = np.random.random(len_input) * 0.1   \n",
    "        self.input = np.ones(len_input)    \n",
    "        self.output = 1   # 对下一层的输出值  \n",
    "        self.deltas_item = 0   # 误差项  \n",
    "        self.last_weight_add = 0   # 上一次权重增加的量\n",
    "  \n",
    "    def calc_output(self, x):  # 计算输出值  \n",
    "        self.input = x  \n",
    "        self.output = logistic(np.dot(self.weights.T, self.input))  \n",
    "        return self.output  \n",
    "  \n",
    "    def get_back_weight(self):  # 获取反馈差值  \n",
    "        return self.weights * self.deltas_item  \n",
    "  \n",
    "    def update_weight(self, target=0, back_weight=0, learning_rate=0.1, layer=\"OUTPUT\"):   # 更新权传  \n",
    "        if layer == \"OUTPUT\":  \n",
    "            self.deltas_item = (target - self.output) * logistic_derivative(self.output)  \n",
    "        elif layer == \"HIDDEN\":  \n",
    "            self.deltas_item = back_weight * logistic_derivative(self.output)  \n",
    "          \n",
    "        weight_add = self.input * self.deltas_item * learning_rate + 0.9 * self.last_weight_add  #添加冲量  \n",
    "        self.weights += weight_add  \n",
    "        self.last_weight_add = weight_add  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#网络层类\n",
    "class NetLayer:\n",
    "    def __init__(self,len_node,in_count): #len_node当前层的神经元数 in_count当前层的输入数\n",
    "        self.neurons = [Neuron(in_count) for _ in range(len_node)] \n",
    "        self.next_layer = None\n",
    "    def calc_output(self, x):  \n",
    "        output = np.array([node.calc_output(x) for node in self.neurons])  \n",
    "        if self.next_layer is not None:  \n",
    "            return self.next_layer.calc_output(output)  \n",
    "        return output  \n",
    "    def get_back_weight(self):  \n",
    "        return sum([node.get_back_weight() for node in self.neurons])  \n",
    "  \n",
    "    def update_weight(self, learning_rate, target):    \n",
    "        layer = \"OUTPUT\"  \n",
    "        back_weight = np.zeros(len(self.neurons))  \n",
    "        if self.next_layer is not None:  \n",
    "            back_weight = self.next_layer.update_weight(learning_rate, target)  \n",
    "            layer = \"HIDDEN\"  \n",
    "        for i, node in enumerate(self.neurons):  \n",
    "            target_item = 0 if len(target) <= i else target[i]  \n",
    "            node.update_weight(target= target_item, back_weight=back_weight[i], learning_rate=learning_rate, layer=layer)  \n",
    "        return self.get_back_weight() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#神经网络类\n",
    "class NeuralNetWork:  \n",
    "    def __init__(self, layers):  \n",
    "        self.layers = []  \n",
    "        self.construct_network(layers)  \n",
    "        pass  \n",
    "  \n",
    "    def construct_network(self, layers):  \n",
    "        last_layer = None  \n",
    "        for i, layer in enumerate(layers):  \n",
    "            if i == 0:  \n",
    "                continue  \n",
    "            cur_layer = NetLayer(layer, layers[i-1])  \n",
    "            self.layers.append(cur_layer)  \n",
    "            if last_layer is not None:  \n",
    "                last_layer.next_layer = cur_layer  \n",
    "            last_layer = cur_layer  \n",
    "  \n",
    "    def training(self, training_data, destination, learning_rate=0.1, epochs=1, shuffle=False):    \n",
    "        indices = np.arange(len(training_data))  \n",
    "        for _ in range(epochs):  \n",
    "            if shuffle:  \n",
    "                np.random.shuffle(indices)  \n",
    "            for i in indices:  \n",
    "                self.layers[0].calc_output(training_data[i])  \n",
    "                self.layers[0].update_weight(learning_rate, destination[i])  \n",
    "        pass  \n",
    "  \n",
    "    def predicting(self, x):  \n",
    "        return self.layers[0].calc_output(x)  \n",
    "    \n",
    "    def varify(self,test_data,destination):\n",
    "        data_quantity, feature_dimension = np.shape(test_data)\n",
    "        print(\"test data quantity:\", data_quantity)\n",
    "        correct = 0\n",
    "        for i in range(0,data_quantity):\n",
    "            if self.predicting(test_data[i]) == destination[i] :\n",
    "                correct +=1\n",
    "        return correct/data_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test neural network\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "test data quantity: 10000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aa42470a028e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvarify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iter \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", Testing Accuracy \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" ,l = \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-dfa14d7e512b>\u001b[0m in \u001b[0;36mvarify\u001b[0;34m(self, test_data, destination)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_quantity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdestination\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdata_quantity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    print(\"test neural network\")\n",
    "    \n",
    "    mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)  #载入数据集\n",
    "  \n",
    "    for epoch in range(21):\n",
    "        network = NeuralNetWork([784, 3, 10])\n",
    "        training_data = mnist.train.images\n",
    "        training_label = mnist.train.labels\n",
    "        #print(training_data[0])\n",
    "        #print(training_label[0])\n",
    "        network.training(training_data, training_label, learning_rate=0.1, epochs=1)\n",
    "        \n",
    "        test_data = mnist.test.images\n",
    "        test_label = mnist.test.labels\n",
    "        \n",
    "        acc = network.varify(test_data,test_label)  \n",
    "        print(\"Iter \" + str(epoch) + \", Testing Accuracy \" + str(acc)+\" ,Learning Rate \"+str(l)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
